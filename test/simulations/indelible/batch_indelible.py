#!/usr/bin/python
"""
Batch INDELible
Write control.txt file and execute indelible to simulate sequences.

Use INDELible partitions to simulate recombination, by using different trees for partition of the genome.
Use INDELible partitions to simulate genome with genes with different mutation rates by using
 same tree but varying tree length across partitions.

Read in partitions via CSV with headers TreeFile, TreeLen, Codons.
"""

import sys
import os
import subprocess
import csv
from argparse import ArgumentParser
import indelible_handler
import tempfile
import shutil
import Utility

INDELIBLE_SITE_INFO_START = 8  # The line that the site information actually starts on.  Line is 0-based. Sites are 1-based




# dN/dS values following a discrete gamma distro
# Gamma(shape=1.5, rate=3), histogram with 50 breaks
OMEGAS = [0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95, 1.05, 1.15, 1.25, 1.35, 1.45, 1.55, 1.65,
        1.75, 1.85, 1.95, 2.05, 2.15, 2.25, 2.35, 2.45, 2.55, 2.65, 2.75, 2.85, 2.95, 3.05, 3.15, 3.25, 3.35,
        3.45, 3.55, 3.65, 3.75, 3.85, 3.95, 4.05, 4.15, 4.25, 4.35, 4.45, 4.55, 4.65, 4.75, 4.85, 4.95, 5.05,
        5.15, 5.25, 5.35, 5.45, 5.55, 5.65, 5.75, 5.85, 5.95, 6.05]

# Probabilities of each discrete gamma distro category in OMEGAS
PROP = [0.1038610, 0.1432928, 0.1381003, 0.1212857, 0.1020363, 0.0835798, 0.0673901, 0.0535906,
        0.0422005, 0.0329969, 0.0258732, 0.0200207, 0.0154661, 0.0118681, 0.0090903, 0.0070075,
        0.0053782, 0.0040914, 0.0031212, 0.0023785, 0.0017896, 0.0013684, 0.0010189, 0.0007866,
        0.0005856, 0.0004496, 0.0003366, 0.0002510, 0.0001857, 0.0001455, 0.0001097, 0.0000839,
        0.0000653, 0.0000442, 0.0000391, 0.0000294, 0.0000200, 0.0000160, 0.0000124, 0.0000084,
        0.0000066, 0.0000052, 0.0000031, 0.0000022, 0.0000017, 0.0000016, 0.0000009, 0.0000008,
        0.0000008, 0.0000003, 0.0000002, 0.0000002, 0.0000002, 0.0000001, 0.0000003, 0.0000001,
        0.0000002, 0.0000001, 0.0000001, 0.0000001, 0.0000001]

KAPPA = 8.0  # Transition/Transversion ratio





parser = ArgumentParser()
parser.add_argument("-p", help="Filepath to Partition CSV containing columns TreeFile, TreeLen, Codons to describe each genome partition")
parser.add_argument("-o", help="output directory for population genome fasta, ancestral fasta")
parser.add_argument("-f", help="output file prefix  (do not specify directory) for genome fasta, ancestral fasta")
parser.add_argument("-i", help="INDELible executable parent directory")
parser.add_argument("-s", help="integer random seed", type=int)

args = parser.parse_args()
if not len(vars(args)):
    parser.print_usage()
    sys.exit()


partition_csv = args.p
output_dir = args.o
output_filename_prefix = args.f
indelible_bin_dir = args.i
seed = args.s


partitions = []
# Keep track of unique Trees separately for INDELible control.txt file, so that we don't write the same Tree multiple times
trees = set([])

with open(partition_csv, 'rU') as fh_in:
    reader = csv.DictReader(fh_in)
    # Check that required headers exist in csv
    for field in indelible_handler.Partition._fields:
        if field not in reader.fieldnames:
            raise ValueError("Missing column " + field + " in INDELible partition configuration csv " + partition_csv +
                             ".  Must contain columns " + ", ".join(indelible_handler.Partition.field_names))

    # Keep track of partitions via a list of Partition namedtuples
    for row in reader:
        # convert csv.DictReader dict to Partition namedtuple
        partition = indelible_handler.Partition(**{k: v for k, v in row.items() if k in indelible_handler.Partition._fields})
        partitions.append(partition)

        tree = indelible_handler.Tree(**{k: v for k, v in row.items() if k in indelible_handler.Tree._fields})
        trees.add(tree)


if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# The *.fasta files contain the unaligned sequences of the leaves (the current individuals in the population).
# The *_TRUE.fasta files contain the aligned sequences of the leaves (the current individuals in the population).
# The *_ANCESTRAL.fasta files contain the sequences of the inner nodes (the ancestors of the population).
output_fasta = output_dir + os.sep + "{}_TRUE.fasta".format(output_filename_prefix)
ancestral_fasta = output_dir + os.sep + "{}_ANCESTRAL.fasta".format(output_filename_prefix)
# The *_RATES.txt file are autogenerated by indelible and contain Site --> discrete omega category mappings
output_rates_txt = output_dir + os.sep + "{}_RATES.txt".format(output_filename_prefix)
# The *_RATES.csv file are autogenerated by us and contain Site --> omega, scaling rate mappings
output_rates_csv = output_dir + os.sep + "{}_RATES.csv".format(output_filename_prefix)
# Consensus of population sequences generated by us
full_popn_cons_fasta = output_dir + os.sep + "{}.consensus.fasta".format(output_filename_prefix)

print "Creating indelible output for partition csv " + partition_csv + " to " + output_fasta

# Do not overwrite existing output files
if (os.path.exists(output_fasta) and os.path.getsize(output_fasta) > 0 and
        os.path.exists(ancestral_fasta) and os.path.getsize(ancestral_fasta) and
        os.path.exists(output_rates_csv) and os.path.getsize(output_rates_csv) and
        os.path.exists(full_popn_cons_fasta) and os.path.getsize(full_popn_cons_fasta)):
    print(output_fasta + " and other output files already exists.  Not regenerating")
else:
    # Write the control.txt file into the output directory.
    # Set the working directory of indelible to that output dir so that we can run indelible without clobbering previous results
    with open(output_dir + os.sep + 'control.txt', 'w') as handle:
        # write minimal contents of INDELible control file
        handle.write('[TYPE] CODON 1\n')
        handle.write('[SETTINGS]\n')
        handle.write('[ancestralprint] NEW\n')  # output ancestral sequences in separate file
        handle.write('[output] FASTA\n') # NB:  indelible nexus file only contains the alignment not the tree.  Might as well use fasta since more common format.
        handle.write('[fastaextension] fasta\n')
        handle.write('[printrates] TRUE\n')
        handle.write('[randomseed] ' + str(seed) + '\n')
        handle.write('[MODEL] M3\n[submodel] %f\n' % KAPPA)  # KAPPA is Transition/Transversion ratio

        prop_string = ''
        omega_string = ''
        for i, omega in enumerate(OMEGAS):
            if i < (len(OMEGAS)-1):
                prop_string += ' %f' % PROP[i]  # probability of each dn/ds value
            omega_string += ' %1.2f' % omega  # dn/ds values follow discrete gamma distro

        handle.write(prop_string + '\n')
        handle.write(omega_string + '\n')

        for tree in trees:
            with open(tree.TreeFile, 'rU') as fh_in_tree:
                tree_string = fh_in_tree.readline()
            treename = "{}_{}".format(os.path.basename(tree.TreeFile), tree.TreeLen)
            handle.write('[TREE] {} {}\n'.format(treename, tree_string))
            handle.write('\t[treelength] {}\n'.format(tree.TreeLen))


        handle.write('[PARTITIONS] partitionname\n')
        for partition in partitions:
            treename = "{}_{}".format(os.path.basename(partition.TreeFile), partition.TreeLen)
            handle.write('\t[{} M3 {}]\n'.format(treename, partition.Codons))


        handle.write('[EVOLVE] partitionname 1 {}\n'.format(output_filename_prefix))

    # INDELible uses the control.txt file in its current working directory
    subprocess.check_call([indelible_bin_dir + os.sep + "indelible"], env=os.environ, cwd=output_dir)

    # INDELible adds extra whitespace at end of fastas.  Get rid of them.
    tmp = tempfile.NamedTemporaryFile(delete=False)
    tmp.close()
    for bad_fasta in [output_fasta, ancestral_fasta]:
        with open(bad_fasta, "rU") as fh_in_fasta, open(tmp.name, 'w') as fh_tmp_out:
            for line in fh_in_fasta:
                line = line.rstrip().lstrip()
                fh_tmp_out.write(line + "\n")
        shutil.copy(tmp.name, bad_fasta)
    os.remove(tmp.name)



    # Copy the contents of the *_RATES.txt autogenerated by indelible
    # and append the site dN/dS  (omega) values, and Tree Lengths (scaling rates)
    # Indelible does not output these by default since it allows for different dN/dS per branch
    # (although only 1 dN/dS class per site)
    with open(output_rates_txt, 'rU') as fh_in, open(output_rates_csv, 'w') as fh_out:
        for line_ctr, line in enumerate(fh_in):
            if line_ctr >= INDELIBLE_SITE_INFO_START:
                break

        reader = csv.DictReader(fh_in, delimiter="\t")
        writer = csv.DictWriter(fh_out, fieldnames=reader.fieldnames + ["Omega", "Tree", "ScalingRate"])
        writer.writeheader()
        for row in reader:
            # Cols: Site	Class	Partition	Inserted?
            site_class = int(row["Class"])  # classes are 0-based numbers.  The discrete category corresponding to the OMEGA value.
            site_omega = OMEGAS[site_class]
            outrow = row
            outrow["Omega"] = site_omega

            partition_idx = int(row["Partition"]) -1  #1-based partition index
            outrow["ScalingRate"] = partitions[partition_idx].TreeLen
            outrow["Tree"] = partitions[partition_idx].TreeFile
            writer.writerow(outrow)


    # Create population  consensus fasta
    Utility.write_consensus_from_msa(msa_fasta_filename=output_fasta, consensus_fasta_filename=full_popn_cons_fasta)





